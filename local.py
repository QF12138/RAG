import re
import os
import json
from langchain.document_loaders.base import BaseLoader
from langchain.docstore.document import Document
from langchain_experimental.text_splitter import SemanticChunker
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers.ensemble import EnsembleRetriever
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader
from sentence_transformers import CrossEncoder
from langchain.text_splitter import RecursiveCharacterTextSplitter
import torch
from openai import OpenAI
os.environ["TRANSFORMERS_OFFLINE"] = "1"

# ----------------------
# è‡ªåŠ¨å¤„ç† JSON æ–‡ä»¶æ¨¡å—
# ----------------------
class AutoJSONProcessor(BaseLoader):
    """
    è‡ªåŠ¨å¤„ç† JSON æ–‡ä»¶çš„åŠ è½½å™¨ï¼š
    - é€’å½’æå– JSON æ•°æ®ä¸­æ‰€æœ‰å­—ç¬¦ä¸²å†…å®¹ã€‚
    - å°†æå–çš„æ–‡æœ¬æ‹¼æ¥æˆæ•´ä½“ï¼Œç”Ÿæˆ Document å¯¹è±¡ã€‚
    """
    def __init__(self, file_path: str, encoding: str = "utf-8"):
        self.file_path = file_path
        self.encoding = encoding

    @staticmethod
    def extract_text(data):
        texts = []
        if isinstance(data, str):
            texts.append(data)
        elif isinstance(data, dict):
            for value in data.values():
                texts.extend(AutoJSONProcessor.extract_text(value))
        elif isinstance(data, list):
            for item in data:
                texts.extend(AutoJSONProcessor.extract_text(item))
        return texts

    def load(self):
        with open(self.file_path, "r", encoding=self.encoding) as f:
            data = json.load(f)
        texts = self.extract_text(data)
        content = " ".join(texts).strip()
        documents = []
        if content:
            documents.append(Document(page_content=content, metadata={"source": self.file_path}))
        return documents


# æ–‡ä»¶é€’å½’
class RecursiveLoader:
    def __init__(self, directory: str, file_extension: str = "*.json"):
        self.directory = directory
        self.file_extension = file_extension

    def load_files(self):
        # ä½¿ç”¨ DirectoryLoader æ¥é€’å½’åŠ è½½æ–‡ä»¶
        loader = DirectoryLoader(self.directory, glob=f"**/{self.file_extension}", loader_cls=AutoJSONProcessor)
        return loader.load()


# ----------------------
# 1. æ™ºèƒ½åˆ†å—é¢„å¤„ç†
# ----------------------
class SmartDocumentProcessor:
    def __init__(self):
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨ HuggingFace çš„ BAAI/bge-small-zh-v1.5 æ¨¡å‹ï¼ˆä¸“ä¸º RAG è®¾è®¡ï¼‰
        model_local_path = os.path.abspath("../../models/bge-small-zh-v1.5")
        self.embed_model = HuggingFaceEmbeddings(
            model_name=model_local_path,
            model_kwargs={"local_files_only": True, "device": "cuda"},
            encode_kwargs={"batch_size": 16}
        )

    def _detect_content_type(self, text):
        """åŠ¨æ€å†…å®¹ç±»å‹æ£€æµ‹"""
        if re.search(r'def |import |print\(|ä»£ç ç¤ºä¾‹', text):
            return "code"
        elif re.search(r'\|.+\|', text) and '%' in text:
            return "table"
        return "normal"

    def process_documents(self):
        # åŠ è½½æ–‡æ¡£ï¼šæ”¯æŒ PDFã€TXT å’Œ JSON æ–‡ä»¶
        loaders = [
            DirectoryLoader("../../knowledge_base", glob="**/*.pdf", loader_cls=PyPDFLoader),
            DirectoryLoader("../../knowledge_base", glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"}),
            DirectoryLoader("../../knowledge_base", glob="**/*.json", loader_cls=AutoJSONProcessor, loader_kwargs={"encoding": "utf-8"})
        ]
        documents = []
        for loader in loaders:
            documents.extend(loader.load())

        # ä½¿ç”¨è¯­ä¹‰åˆ†å—å™¨å¯¹æ–‡æ¡£è¿›è¡Œåˆæ­¥åˆ†å—
        chunker = SemanticChunker(
            embeddings=self.embed_model,
            breakpoint_threshold_amount=82,
            add_start_index=True
        )
        base_chunks = chunker.split_documents(documents)

        # äºŒæ¬¡åŠ¨æ€åˆ†å—ï¼Œæ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ä¸åŒçš„åˆ†å—å‚æ•°
        final_chunks = []
        for chunk in base_chunks:
            content_type = self._detect_content_type(chunk.page_content)
            if content_type == "code":
                splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=64)
            elif content_type == "table":
                splitter = RecursiveCharacterTextSplitter(chunk_size=384, chunk_overlap=96)
            else:
                splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)
            final_chunks.extend(splitter.split_documents([chunk]))
        # ä¸ºæ¯ä¸ªå—æ·»åŠ å…ƒæ•°æ®
        for i, chunk in enumerate(final_chunks):
            chunk.metadata.update({
                "chunk_id": f"chunk_{i}",
                "content_type": self._detect_content_type(chunk.page_content)
            })
        return final_chunks


# ----------------------
# 2. æ··åˆæ£€ç´¢ç³»ç»Ÿ
# ----------------------
class HybridRetriever:
    def __init__(self, chunks):
        # æ„å»ºå‘é‡æ•°æ®åº“ï¼Œä½¿ç”¨ Chroma å­˜å‚¨æ–‡æ¡£å—ï¼ŒåµŒå…¥æ¨¡å‹ä¸º BAAI/bge-large-zh-v1.5
        self.vector_db = Chroma.from_documents(
            chunks,
            embedding=HuggingFaceEmbeddings(
                model_name="../../models/bge-large-zh-v1.5",
                model_kwargs={"local_files_only": True, "device": "cuda"}
            ),
            persist_directory="../../vector_db"
        )

        self.bm25_retriever = BM25Retriever.from_documents(chunks, k=5)
        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[
                self.vector_db.as_retriever(search_kwargs={"k": 5}),
                self.bm25_retriever
            ],
            weights=[0.6, 0.4]
        )
        self.reranker = CrossEncoder(
            "../../models/bge-reranker-large",
            device="cuda" if torch.backends.cuda.is_built() else "cpu"
        )

    def retrieve(self, query, top_k=3):
        docs = self.ensemble_retriever.invoke(query)  # ä½¿ç”¨æ–°æ–¹æ³• 'invoke'
        pairs = [[query, doc.page_content] for doc in docs]
        scores = self.reranker.predict(pairs)
        ranked_docs = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
        return [doc for doc, _ in ranked_docs[:top_k]]


# ----------------------
# 3. RAGç³»ç»Ÿé›†æˆ
# ----------------------
class EnhancedRAG:
    def __init__(self):
        # æ–‡æ¡£é¢„å¤„ç†
        processor = SmartDocumentProcessor()
        chunks = processor.process_documents()
        self.retriever = HybridRetriever(chunks)

        # åˆå§‹åŒ–DeepSeek APIå®¢æˆ·ç«¯
        self.client = OpenAI(api_key="sk-996a6e8eeec94ce4be8d44acb3f40189",
                             base_url="https://api.deepseek.com")

        with open("../../banned_keywords.TXT", encoding='UTF-8') as f:
            self.banned_keywords = f.read().split()  # è¿è§„å…³é”®è¯åˆ—è¡¨

    def is_geological_question(self, question):
        """åˆ¤æ–­æ˜¯å¦ä¸ºåœ°è´¨ç›¸å…³é—®é¢˜"""
        geo_keywords = ["å²©ä½“", "å›´å²©", "éš§é“", "åœ°è´¨", "èŠ‚ç†", "åœ°ä¸‹æ°´", "å¼€æŒ–"]
        return any(keyword in question for keyword in geo_keywords)

    def generate_prompt(self, question, contexts):
        # ä¿ç•™åŸæœ‰promptç”Ÿæˆé€»è¾‘
        context_str = "\n\n".join(
            [f"[æ¥æºï¼š{doc.metadata['source']}ï¼Œç±»å‹ï¼š{doc.metadata['content_type']}]\n{doc.page_content}"
             for doc in contexts])

        return f"""
å½“å‰ä¸Šä¸‹æ–‡:
{context_str}

è¾“å…¥ä¸è¾“å‡ºç¤ºä¾‹å¦‚ä¸‹ï¼š
ç¤ºä¾‹ä¸€ï¼šå¼€æŒ–æ­ç¤ºå›´å²©ä¸ºç»†ç²’äºŒé•¿èŠ±å²—å²©ï¼Œæ·±ç°è‰²ã€è¤ç°è‰²ï¼Œå¼±é£åŒ–ä¸ºä¸»ï¼ŒèŠ‚ç†è£‚éš™è¾ƒå‘è‚²ï¼Œä¸»è¦å‘è‚²ä¸¤ç»„èŠ‚ç†ï¼Œâ‘ å·ä¸»æ§èŠ‚ç†N40Â°W/75Â°SWï¼Œâ‘¡N50Â°W/70Â°NEï¼Œè´¯é€šæ€§è¾ƒå¥½ï¼Œç»“åˆå·®ï¼Œå²©ä½“è¾ƒç ´ç¢ï½ç ´ç¢ï¼Œå›´å²©æ•´ä½“ç¨³å®šæ€§ä¸€èˆ¬ï¼Œæ‰å—é£é™©è¾ƒé«˜ï¼ŒæŒå­é¢å·¦ä¾§å‘è‚²èŠ‚ç†å¯†é›†å¸¦ï¼Œæœ‰èš€å˜ç°è±¡ï¼Œå²©è´¨è½¯ï¼Œæ‰‹ææ˜“ç¢ï¼Œç¨³å®šæ€§å·®ï¼Œæ‰å—ä¸¥é‡ï¼Œä¸”åå¡Œé£é™©é«˜ï¼ŒæŒå­é¢æ¹¿æ¶¦ï¼Œæ¸—æ°´ï¼Œå·¦ä¾§å²©ä½“å‘ˆçº¿æµçŠ¶å‡ºæ°´ï¼Œæ‹±é¡¶æ·‹é›¨çŠ¶å‡ºæ°´ï¼Œè¶…å‰æ¢å­”è‚¡çŠ¶å‡ºæ°´ã€‚
ç­”æ¡ˆï¼š
    å·¥ç¨‹åœ°è´¨ä¿¡æ¯:
        åœ°å±‚å²©æ€§:ç»†ç²’äºŒé•¿èŠ±å²—å²©
        åœ°è´¨æ„é€ :èŠ‚ç†è£‚éš™è¾ƒå‘è‚²ï¼Œä¸»è¦å‘è‚²ä¸¤ç»„èŠ‚ç†ï¼Œâ‘ å·ä¸»æ§èŠ‚ç†N40Â°W/75Â°SWï¼Œâ‘¡N50Â°W/70Â°NEï¼Œè´¯é€šæ€§è¾ƒå¥½ï¼Œç»“åˆå·®ï¼Œå²©ä½“è¾ƒç ´ç¢ï½ç ´ç¢ï¼Œå›´å²©æ•´ä½“ç¨³å®šæ€§ä¸€èˆ¬ï¼Œæ‰å—é£é™©è¾ƒé«˜ï¼ŒæŒå­é¢å·¦ä¾§å‘è‚²èŠ‚ç†å¯†é›†å¸¦
        å²©æº¶:æœ‰èš€å˜ç°è±¡ï¼Œå²©è´¨è½¯ï¼Œæ‰‹ææ˜“ç¢ï¼Œç¨³å®šæ€§å·®ï¼Œæ‰å—ä¸¥é‡ï¼Œä¸”åå¡Œé£é™©é«˜
        ç‰¹æ®Šåœ°å±‚:æ— ç›¸å…³ä¿¡æ¯
        äººä¸ºå‘æ´:æ— ç›¸å…³ä¿¡æ¯
        åœ°åº”åŠ›:æ— ç›¸å…³ä¿¡æ¯
        å¡Œæ–¹:æ— ç›¸å…³ä¿¡æ¯
        å…¶ä»–:æ— ç›¸å…³ä¿¡æ¯
    æ°´æ–‡åœ°è´¨:
        åœ°ä¸‹æ°´ä¿¡æ¯:æŒå­é¢æ¹¿æ¶¦ï¼Œæ¸—æ°´ï¼Œå·¦ä¾§å²©ä½“å‘ˆçº¿æµçŠ¶å‡ºæ°´ï¼Œæ‹±é¡¶æ·‹é›¨çŠ¶å‡ºæ°´ï¼Œè¶…å‰æ¢å­”è‚¡çŠ¶å‡ºæ°´
        æ°´è´¨åˆ†æ:æ— ç›¸å…³ä¿¡æ¯
        å…¶ä»–:æ— ç›¸å…³ä¿¡æ¯
    ç»¼åˆåˆ†æ:
        å²©çŸ³åšç¡¬ç¨‹åº¦:åšç¡¬å²©
        ç†ç”±:åŸå²©ä¸ºç»†ç²’äºŒé•¿èŠ±å²—å²©ï¼Œå±äºåšç¡¬å²©ï¼Œå—åˆ°å¼±é£åŒ–ï¼Œæ‰€ä»¥ä¸ºåšç¡¬å²©
        å²©ä½“å®Œæ•´ç¨‹åº¦:è¾ƒç ´ç¢
        ç†ç”±:ä¸»è¦ç»“æ„é¢ç±»å‹èŠ‚ç†è£‚éš™è¾ƒå‘è‚²ï¼Œå‘è‚²ä¸¤ç»„èŠ‚ç†ï¼Œè´¯é€šæ€§è¾ƒå¥½ï¼Œç»“åˆå·®ï¼Œå›´å²©æ•´ä½“ç¨³å®šæ€§ä¸€èˆ¬ï¼Œæ‰å—é£é™©è¾ƒé«˜
        åœ°ä¸‹æ°´çŠ¶æ€:â…¡
        ç†ç”±:æŒå­é¢æ¹¿æ¶¦ï¼Œæ¸—æ°´ï¼Œå·¦ä¾§å²©ä½“å‘ˆçº¿æµçŠ¶å‡ºæ°´ï¼Œæ‹±é¡¶æ·‹é›¨çŠ¶å‡ºæ°´ï¼Œè¶…å‰æ¢å­”è‚¡çŠ¶å‡ºæ°´
ç¤ºä¾‹äºŒï¼šæŒå­é¢æ­ç¤ºå›´å²©ä¸»è¦ä¸ºäºŒé•¿èŠ±å²—å²©ï¼Œç°é»‘è‰²ï¼Œå±€éƒ¨å¤¹æ·±ç°è‰²ã€è¤é»„è‰²ï¼Œå¼±é£åŒ–ä¸ºä¸»ï¼Œå±€éƒ¨å¤¹å¼ºé£åŒ–ï¼ŒèŠ‚ç†è£‚éš™è¾ƒå‘è‚²ï¼Œå»¶ä¼¸è¾ƒå¥½ï¼Œå±€éƒ¨èŠ‚ç†é¢å¯è§é“è´¨ä¾µæŸ“ï¼Œä¸»è¦èŠ‚ç†äº§çŠ¶ï¼šN70Â°E/70Â°NWã€N30Â°W/55Â°SWï¼ŒæŒå­é¢å‘è‚²å¤šæ¡çŸ³è‹±è„‰ï¼Œå®½5ï½10cmï¼Œå²©ä½“æ•´ä½“è¾ƒå®Œæ•´ï¼Œå±€éƒ¨è¾ƒç ´ç¢ï¼Œæœ‰æ‰å—å‰¥è½ç°è±¡ã€‚æŒå­é¢æ•´ä½“æ¹¿æ¶¦ï¼Œå±€éƒ¨å‘ˆçº¿çŠ¶å’Œè‚¡çŠ¶å‡ºæ°´ï¼Œå•ä½æ¸—æ°´é‡30L/(minÂ·10m) ã€‚
ç­”æ¡ˆï¼š
    å·¥ç¨‹åœ°è´¨ä¿¡æ¯:
        åœ°å±‚å²©æ€§:äºŒé•¿èŠ±å²—å²©ï¼Œç°é»‘è‰²ï¼Œå±€éƒ¨å¤¹æ·±ç°è‰²ã€è¤é»„è‰²
        åœ°è´¨æ„é€ :èŠ‚ç†è£‚éš™è¾ƒå‘è‚²ï¼Œå»¶ä¼¸è¾ƒå¥½ï¼Œå±€éƒ¨èŠ‚ç†é¢å¯è§é“è´¨ä¾µæŸ“ï¼Œä¸»è¦èŠ‚ç†äº§çŠ¶ï¼šN70Â°E/70Â°NWã€N30Â°W/55Â°SWï¼ŒæŒå­é¢å‘è‚²å¤šæ¡çŸ³è‹±è„‰ï¼Œå®½5ï½10cmï¼Œå²©ä½“æ•´ä½“è¾ƒå®Œæ•´ï¼Œå±€éƒ¨è¾ƒç ´ç¢ï¼Œæœ‰æ‰å—å‰¥è½ç°è±¡
        å²©æº¶:æ— ç›¸å…³ä¿¡æ¯
        ç‰¹æ®Šåœ°å±‚:æ— ç›¸å…³ä¿¡æ¯
        äººä¸ºå‘æ´:æ— ç›¸å…³ä¿¡æ¯
        åœ°åº”åŠ›:æ— ç›¸å…³ä¿¡æ¯
        å¡Œæ–¹:æ— ç›¸å…³ä¿¡æ¯
        å…¶ä»–:æ— ç›¸å…³ä¿¡æ¯
    æ°´æ–‡åœ°è´¨:
        åœ°ä¸‹æ°´ä¿¡æ¯:æŒå­é¢æ•´ä½“æ¹¿æ¶¦ï¼Œå±€éƒ¨å‘ˆçº¿çŠ¶å’Œè‚¡çŠ¶å‡ºæ°´ï¼Œå•ä½æ¸—æ°´é‡30L/(minÂ·10m)
        æ°´è´¨åˆ†æ:æ— ç›¸å…³ä¿¡æ¯
        å…¶ä»–:æ— ç›¸å…³ä¿¡æ¯
    ç»¼åˆåˆ†æ:
        å²©çŸ³åšç¡¬ç¨‹åº¦:åšç¡¬å²©
        ç†ç”±:åŸå²©ä¸ºäºŒé•¿èŠ±å²—å²©ï¼Œå±äºAç±»å²©ï¼Œç¡¬åº¦é«˜ï¼Œå—åˆ°å¼±é£åŒ–ä¸ºä¸»ï¼Œå±€éƒ¨å¼ºé£åŒ–ï¼Œæ‰€ä»¥æ•´ä½“ä¸ºåšç¡¬å²©
        å²©ä½“å®Œæ•´ç¨‹åº¦:è¾ƒå®Œæ•´
        ç†ç”±:èŠ‚ç†è¾ƒå‘è‚²ï¼Œä¸»è¦å‘è‚²ä¸¤ç»„èŠ‚ç†ï¼Œæ•…å¯èƒ½ä¸ºè¾ƒå®Œæ•´~è¾ƒç ´ç¢ï¼›æ ¹æ®å±€éƒ¨èŠ‚ç†é¢å¯è§é“è´¨ä¾µæŸ“ï¼Œå¯ä»¥è®¤ä¸ºç»“æ„é¢ç»“åˆç¨‹åº¦ä¸€èˆ¬ï¼›æœ€åç»“åˆä¿¡æ¯å²©ä½“æ•´ä½“è¾ƒå®Œæ•´ï¼Œå±€éƒ¨è¾ƒç ´ç¢å¯ä»¥è®¤ä¸ºå²©ä½“æ•´ä½“è¾ƒå®Œæ•´
        åœ°ä¸‹æ°´çŠ¶æ€:â…¡
        ç†ç”±:æŒå­é¢æ•´ä½“æ¹¿æ¶¦ï¼Œå±€éƒ¨å‘ˆçº¿çŠ¶å’Œè‚¡çŠ¶å‡ºæ°´ï¼Œå•ä½æ¸—æ°´é‡30L/(minÂ·10m)
ç¤ºä¾‹ä¸‰ï¼šç²—è§’ç ¾åœŸï¼Œè¤é»„è‰²ï¼Œè§’ç ¾å«é‡çº¦65ï¼…ï¼Œå‘ˆæ£±è§’çŠ¶ã€æ¬¡æ£±è§’çŠ¶ï¼Œå±€éƒ¨å¤¹å°‘é‡ç¢çŸ³åœŸ,ä¸­å¯†çŠ¶ï¼Œæ½®æ¹¿ï¼Œç ¾çŸ³æˆåˆ†ä¸ºèŠ±å²—å²©è´¨ã€‚ç²’å¾„ 20ï½120mmï¼Œå°–æ£±çŠ¶ï¼Œå……å¡«ç²‰è´¨é»åœŸã€‚æŒå­é¢æ— æ°´ï¼Œæ•´ä½“æ¹¿æ¶¦ï¼Œæœ‰æ‰å—ç°è±¡ï¼Œå›´å²©ç¨³å®šæ€§è¾ƒå·®.
ç­”æ¡ˆï¼š
    åœŸä½“ä¿¡æ¯ï¼šç²—è§’ç ¾åœŸï¼Œè¤é»„è‰²ï¼Œè§’ç ¾å«é‡çº¦65ï¼…ï¼Œå‘ˆæ£±è§’çŠ¶ã€æ¬¡æ£±è§’çŠ¶ï¼Œå±€éƒ¨å¤¹å°‘é‡ç¢çŸ³åœŸ,ä¸­å¯†çŠ¶ï¼Œæ½®æ¹¿ï¼Œç ¾çŸ³æˆåˆ†ä¸ºèŠ±å²—å²©è´¨ã€‚ç²’å¾„ 20ï½120mmï¼Œå°–æ£±çŠ¶ï¼Œå……å¡«ç²‰è´¨é»åœŸ
    åœ°ä¸‹æ°´ä¿¡æ¯:æŒå­é¢æ— æ°´ï¼Œæ•´ä½“æ¹¿æ¶¦
    åœ°è´¨æ„é€ ï¼šæœ‰æ‰å—ç°è±¡ï¼Œå›´å²©ç¨³å®šæ€§è¾ƒå·®
    ç»¼åˆåˆ†æï¼š
        åœ°ä¸‹æ°´çŠ¶æ€:â… 
        ç†ç”±:æŒå­é¢æ— æ°´ï¼Œæ•´ä½“æ¹¿æ¶¦

ç°åœ¨åˆ†æå¾—åˆ°çš„ä¿¡æ¯:{question}
é¦–å…ˆæå–å‡ºç›¸å…³æ¨¡æ¿ä¿¡æ¯ï¼Œç„¶åæ ¹æ®æœ‰å…³å²©çŸ³åšç¡¬ç¨‹åº¦ã€å²©ä½“å®Œæ•´ç¨‹åº¦ã€åœ°ä¸‹æ°´çŠ¶æ€çš„æè¿°ä¿¡æ¯å¹¶ç»™å®ƒä»¬è¿›è¡Œå®šæ€§,å®šæ€§æ—¶å¿…é¡»è¦ç»™å‡ºç†ç”±ä¸”è¦æœ‰åˆ†ææå–ä¿¡æ¯çš„è¿‡ç¨‹ã€‚
æ³¨æ„ï¼š
1.å¦‚æœç”¨æˆ·æä¾›ä¿¡æ¯å’Œéš§é“ï¼Œåœ°è´¨æ— å…³ï¼Œè¯·ç‹¬ç«‹æ€è€ƒå¹¶å›å¤ï¼Œä¸éœ€è¦è€ƒè™‘ç¤ºä¾‹å†…å®¹ã€‚
2.è¯·åŠ¡å¿…æŒ‰ç¤ºä¾‹ä¸­çš„æ¨¡æ¿æ ·ä¾‹è¿›è¡Œè¾“å‡ºã€‚       
3.å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºç¼ºå¤±çš„ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œç‹¬ç«‹æ€è€ƒã€‚æœ€åç”¨ä¸­æ–‡ç»™å‡ºç»“æ„åŒ–jsonæ–‡ä»¶å½¢å¼ç­”æ¡ˆã€‚
"""

    def contains_banned_content(self, text):
        """æ£€æµ‹è¿è§„å†…å®¹"""
        return any(keyword in text for keyword in self.banned_keywords)

    def ask(self, question):
        # æ£€æµ‹è¿è§„å†…å®¹
        if self.contains_banned_content(question):
            return "âš ï¸ è¯¥å†…å®¹æ¶‰åŠè¿è§„è¯é¢˜ï¼Œæ— æ³•å›ç­”"

        # éåœ°è´¨é—®é¢˜ç›´æ¥å›ç­”
        if not self.is_geological_question(question):
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"},
                {"role": "user", "content": question}
            ]
        else:
            # åœ°è´¨é—®é¢˜å¤„ç†æµç¨‹
            contexts = self.retriever.retrieve(question)
            prompt = self.generate_prompt(question, contexts)
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåœ°è´¨é¢†åŸŸåŠ©æ‰‹"},
                {"role": "user", "content": prompt},
            ]

        # è°ƒç”¨API
        response = self.client.chat.completions.create(
            model="deepseek-reasoner",
            messages=messages,
            max_tokens=8000,
            stream=False
        )

        # è·å–å›ç­”
        answer = response.choices[0].message.content
        return answer


# ä¿®æ”¹åçš„ä¸»ç¨‹åº
if __name__ == "__main__":
    rag = EnhancedRAG()
    print("è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰")

    while True:
        try:
            user_input = input("\n>>> ç”¨æˆ·: ").strip()
            if user_input.lower() == 'quit':
                print("\nå¯¹è¯ç»“æŸ")
                break

            if not user_input:
                print("é—®é¢˜ä¸èƒ½ä¸ºç©º")
                continue

            print("\nğŸ¤– æ­£åœ¨æ€è€ƒ...", end="", flush=True)
            answer = rag.ask(user_input)
            print("\r" + " " * 20 + "\r", end="")
            print("\nğŸ’¡ ç³»ç»Ÿå›ç­”:")
            print("-" * 50)
            print(answer)
            print("-" * 50)

        except Exception as e:
            print(f"\nâš ï¸ é”™è¯¯: {str(e)}")

